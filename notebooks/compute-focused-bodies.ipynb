{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Focused Bodies\n",
    "\n",
    "This notebook demonstrates how to use `compute_focused_bodies()`, which produces a table of all bodies in the volume that contain a minimum number of synapses or are above a minimum size (in voxels).\n",
    "\n",
    "The synapse/voxel counts are included in the table.\n",
    "\n",
    "You must provide synapses and supervoxel sizes as input to the function, and thus this function does not require any calls to DVID, except for a single call to the `/mappings` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pydoc\n",
    "import logging\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm_notebook\n",
    "tqdm = tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dvidutils import LabelMapper\n",
    "from libdvid import DVIDNodeService\n",
    "\n",
    "from neuclease.dvid import *\n",
    "from neuclease.focused.ingest import compute_focused_bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = logging.StreamHandler(sys.stdout)\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.handlers = []\n",
    "root_logger.addHandler(handler)\n",
    "root_logger.setLevel(logging.INFO)\n",
    "logging.getLogger('kafka').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nrs/flyem/bergs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node/segmentation\n",
    "uuid = '38c6'\n",
    "master_seg = ('emdata3:8900', uuid, 'segmentation')\n",
    "\n",
    "# Synapses file\n",
    "synapse_samples = '/nrs/flyem/bergs/complete-ffn-agglo/sampled-synapses-38c6-locked.csv'\n",
    "\n",
    "# Root SV Size file\n",
    "root_sv_sizes_dir = '/groups/flyem/data/scratchspace/copyseg-configs/labelmaps/hemibrain/8nm/compute-8nm-extended-fixed-STATS-ONLY-20180402.192015'\n",
    "root_sv_sizes = f'{root_sv_sizes_dir}/supervoxel-sizes.h5'\n",
    "\n",
    "# Classification file (from masking model)\n",
    "sv_classifications = '/nrs/flyem/bergs/sv-classifications.h5'\n",
    "\n",
    "# Optional: Manually listed \"bad bodies\" that should be avoided (massive glia, etc.)\n",
    "marked_bad_bodies = '/nrs/flyem/bergs/complete-ffn-agglo/bad-bodies-2018-10-01.csv'\n",
    "\n",
    "# Parameters -- which bodies should be included in the results?\n",
    "# NOTE: A body is included if it satisfies ANY of these\n",
    "#      (doesn't need to satisfy ALL of them)\n",
    "min_tbars = 2\n",
    "min_psds = 10\n",
    "min_body_size = int(10e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute! (Takes ~20 minutes and needs a LOT of RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading kafka messages from ['kafka.int.janelia.org:9092', 'kafka2.int.janelia.org:9092', 'kafka3.int.janelia.org:9092'] for emdata3:8900 / 38c6 / segmentation\n",
      "Reading 1048499 kafka messages took 38.09354639053345 seconds\n",
      "Fetching http://emdata3:8900/api/node/38c6/segmentation/mappings...\n",
      "Fetching http://emdata3:8900/api/node/38c6/segmentation/mappings took 0:00:34.249898\n",
      "Parsing mapping...\n",
      "Parsing mapping took 0:00:06.726146\n",
      "Constructing missing identity-mappings...\n",
      "Constructing missing identity-mappings took 0:00:19.072801\n",
      "Filtering for synapses...\n",
      "*** Synapse table includes body 0 and was therefore probably generated from out-of-date data. ***\n",
      "Filtering for synapses took 0:00:48.365104\n",
      "Found 454774 with sufficient synapses\n",
      "Filtering for body size...\n",
      "Volume contains 188243164 supervoxels and 22.5 Teravoxels in total\n",
      "Reading kafka messages from ['kafka.int.janelia.org:9092', 'kafka2.int.janelia.org:9092', 'kafka3.int.janelia.org:9092'] for emdata3:8900 / 38c6 / segmentation\n",
      "Reading 1048499 kafka messages took 38.317110776901245 seconds\n",
      "Fetching sizes for 10634 split supervoxels...\n",
      "Fetching sizes for 10634 split supervoxels took 0:01:57.185294\n",
      "Dropping unknown supervoxels\n",
      "Applying sizes to mapping\n",
      "Aggregating sizes by body\n",
      "Appending singleton sizes\n",
      "Sorting sizes\n",
      "Filtering for body size took 0:07:36.966717\n",
      "Found 173601 with sufficient size\n",
      "Filtering by supervoxel classifications...\n",
      "Dropping 20072 bodies with more than 50% bad supervoxels\n",
      "Filtering by supervoxel classifications took 0:02:05.096768\n",
      "Dropping 15 bad bodies (from 488075)...\n",
      "Dropping 15 bad bodies (from 488075) took 0:00:00.000058\n",
      "Found 488069 focused bodies\n",
      "Computing full focused table...\n",
      "Computing full focused table took 0:00:01.447672\n"
     ]
    }
   ],
   "source": [
    "# This function does the following:\n",
    "#\n",
    "# 1. Apply synapse-based criteria\n",
    "#   a. Load synapse CSV file\n",
    "#   b. Map synapse SVs -> bodies (if needed)\n",
    "#   c. Calculate synapses (tbars, psds) per body\n",
    "#   d. Initialize set with bodies that have enough synapses\n",
    "\n",
    "# 2. Apply size-based criteria\n",
    "#   a. Calculate body sizes (based on supervoxel sizes and current mapping)\n",
    "#   b. Add \"big\" bodies to the set\n",
    "\n",
    "# 3. Apply \"bad body\" criteria\n",
    "#   a. Read the list of \"bad bodies\"\n",
    "#   b. Remove bad bodies from the set\n",
    "\n",
    "focused_table = compute_focused_bodies( *master_seg,\n",
    "                                        synapse_samples,\n",
    "                                        min_tbars,\n",
    "                                        min_psds,\n",
    "                                        root_sv_sizes,\n",
    "                                        min_body_size,\n",
    "                                        sv_classifications,\n",
    "                                        marked_bad_bodies,\n",
    "                                        return_table=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voxel_count</th>\n",
       "      <th>sv_count</th>\n",
       "      <th>PostSyn</th>\n",
       "      <th>PreSyn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1497973422</th>\n",
       "      <td>12393316998</td>\n",
       "      <td>8977</td>\n",
       "      <td>8485</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5813070019</th>\n",
       "      <td>10958567746</td>\n",
       "      <td>8062</td>\n",
       "      <td>7408</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262840563</th>\n",
       "      <td>10492068511</td>\n",
       "      <td>6347</td>\n",
       "      <td>764</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263199096</th>\n",
       "      <td>10129123402</td>\n",
       "      <td>2867</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947573616</th>\n",
       "      <td>9338261326</td>\n",
       "      <td>8228</td>\n",
       "      <td>19239</td>\n",
       "      <td>4512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            voxel_count  sv_count  PostSyn  PreSyn\n",
       "body                                              \n",
       "1497973422  12393316998      8977     8485      67\n",
       "5813070019  10958567746      8062     7408     100\n",
       "262840563   10492068511      6347      764     647\n",
       "263199096   10129123402      2867       72      50\n",
       "947573616    9338261326      8228    19239    4512"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focused_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = f'focused-{uuid}-{min_tbars}tbars-{min_psds}psds-{min_body_size / 1e6:.1f}Mv'\n",
    "\n",
    "# As npy:\n",
    "np.save(f'{output_name}.npy', focused_table.to_records(index=True))\n",
    "\n",
    "# OR as CSV:\n",
    "#focused_table.to_csv(f'{output_name}.npy', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See docs for more details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Library Documentation: function compute_focused_bodies in module neuclease.focused.ingest\n",
      "\n",
      "c\bco\bom\bmp\bpu\but\bte\be_\b_f\bfo\boc\bcu\bus\bse\bed\bd_\b_b\bbo\bod\bdi\bie\bes\bs(server, uuid, instance, synapse_samples, min_tbars, min_psds, root_sv_sizes, min_body_size, sv_classifications=None, marked_bad_bodies=None, return_table=False)\n",
      "    Compute the complete set of focused bodies, based on criteria for\n",
      "    number of tbars, psds, or overall size, and excluding explicitly\n",
      "    listed bad bodies.\n",
      "    \n",
      "    This function takes ~20 minutes to run on hemibrain inputs, with a ton of RAM.\n",
      "    \n",
      "    The procedure is:\n",
      "    \n",
      "    1. Apply synapse-based criteria\n",
      "      a. Load synapse CSV file\n",
      "      b. Map synapse SVs -> bodies (if needed)\n",
      "      c. Calculate synapses (tbars, psds) per body\n",
      "      d. Initialize set with bodies that have enough synapses\n",
      "    \n",
      "    2. Apply size-based criteria\n",
      "      a. Calculate body sizes (based on supervoxel sizes and current mapping)\n",
      "      b. Add \"big\" bodies to the set\n",
      "    \n",
      "    3. Apply \"bad body\" criteria\n",
      "      a. Read the list of \"bad bodies\"\n",
      "      b. Remove bad bodies from the set\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "        server = 'emdata3:8900'\n",
      "        uuid = '7254'\n",
      "        instance = 'segmentation'\n",
      "        synapse_samples = '/nrs/flyem/bergs/complete-ffn-agglo/sampled-synapses-d585.csv'\n",
      "        min_tbars = 2\n",
      "        min_psds = 10\n",
      "        root_sv_sizes_dir = '/groups/flyem/data/scratchspace/copyseg-configs/labelmaps/hemibrain/8nm/compute-8nm-extended-fixed-STATS-ONLY-20180402.192015'\n",
      "        root_sv_sizes = f'{root_sv_sizes_dir}/supervoxel-sizes.h5'\n",
      "        min_body_size = int(10e6)\n",
      "        sv_classifications = '/nrs/flyem/bergs/sv-classifications.h5'\n",
      "        marked_bad_bodies = '/nrs/flyem/bergs/complete-ffn-agglo/bad-bodies-2018-10-01.csv'\n",
      "        \n",
      "        table_description = f'{uuid}-{min_tbars}tbars-{min_psds}psds-{min_body_size / 1e6:.1f}Mv'\n",
      "        focused_table = compute_focused_bodies(server, uuid, instance, synapse_samples, min_tbars, min_psds, root_sv_sizes, min_body_size, sv_classifications, marked_bad_bodies, return_table=True)\n",
      "    \n",
      "        # As npy:\n",
      "        np.save(f'focused-{table_description}.npy', focused_table.to_records(index=True))\n",
      "    \n",
      "        # As CSV:\n",
      "        focused_table.to_csv(f'focused-{table_description}.npy', index=True, header=True)\n",
      "    \n",
      "    Args:\n",
      "    \n",
      "        server, uuid, instance:\n",
      "            labelmap instance\n",
      "    \n",
      "        root_sv_sizes:\n",
      "            mapping of supervoxel sizes from the root node, as returned by load_supervoxel_sizes(),\n",
      "            or a path to an hdf5 file from which it can be loaded\n",
      "        \n",
      "        synapse_samples:\n",
      "            A DataFrame with columns 'body' (or 'sv') and 'kind', or a path to a CSV file with those columns.\n",
      "            The 'kind' column is expected to have only 'PreSyn' and 'PostSyn' entries.\n",
      "            If the table has an 'sv' column, any \"retired\" supervoxel IDs will be updated before\n",
      "            continuing with the analysis.\n",
      "        \n",
      "        min_tbars:\n",
      "            The minimum number pf PreSyn entries to pass the filter.\n",
      "            Bodies with fewer tbars may still be included if they satisfy the min_psds criteria.\n",
      "        \n",
      "        min_psds:\n",
      "            The minimum numer of PostSyn entires to pass the filter.\n",
      "            Bodies with fewer psds may still pass the filter if they satisfy the min_tbars criteria.\n",
      "    \n",
      "        min_body_size:\n",
      "            Determines which bodies are included on the basis of their size alone,\n",
      "            regardless of synapse count.\n",
      "        \n",
      "        sv_classifications:\n",
      "            Optional. Path to an hdf5 file containing supervoxel classifications.\n",
      "            Must have datasets: 'supervoxel_ids', 'classifications', and 'class_names'.\n",
      "    \n",
      "        marked_bad_bodies:\n",
      "            Optional. A list of known-bad bodies to exclude from the results,\n",
      "            or a path to a .csv file with that list (in the first column),\n",
      "            or a keyvalue instance name from which the list can be loaded as JSON.\n",
      "        \n",
      "        return_table:\n",
      "            If True, return the focused bodies in a DataFrame, indexed by body,\n",
      "            with columns for body size and synapse counts.\n",
      "            If False, simply return the list of bodies (saves about 4 minutes).\n",
      "    \n",
      "    Returns:\n",
      "        A list of body IDs that passed all filters, or a DataFrame with columns:\n",
      "            ['voxel_count', 'PreSyn', 'PostSyn']\n",
      "        (See return_table option.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pydoc.render_doc(compute_focused_bodies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
